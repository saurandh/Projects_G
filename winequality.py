# -*- coding: utf-8 -*-
"""WineQuality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18OwX2hzCjQFq0WZn9mBLlSjUpBejC_9t

# Wine Quality Prediction Project:
"""

#!pip install imbalanced-learn

#!pip install xgboost

#!pip install lightgbm

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.simplefilter("ignore")
import joblib

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import scipy.stats as stats
from scipy.stats import zscore

from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb
import lightgbm as lgb

from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

"""Importing all the dependencies"""

df = pd.read_csv("/content/winequality-red.csv")

"""Instead of downloading the entire dataset on my local computer I am simply loading the file directly from the GitHub repository link using the raw option."""

df # Taking a look at the dataset's first and last 5 rows showcasing all the column names as well

"""So by taking a look at the above data frame I can see that the column quality is the target label making the remaining columns as the features that we can customize and use to predict our label. This classifies to be a Classification problem!

# Exploratory Data Analysis (EDA)
"""

df.shape

"""I see that there are total 1599 rows and 12 columns present in our dataset."""

df.isnull().sum()

"""Luckily we do not see any missing values in any of the columns of our dataset so we don't have to worry about handling missing data."""

df.info()

"""Great none of the columns have any object data type values and our label is the only integer value making all the feature columns as float datatype i.e. similar datatype."""

df.describe()

"""Using the describe method I can see the count, mean, standard deviation, minimum, maximum and inter quantile values of our dataset.

As per my observation:
1. There is a big gap between 75% and max values of residual sugar column
2. There is a big gap between 75% and max values of free sulfur dioxide	column
3. There is a huge gap between 75% and max value of total sulfur dioxide column

All these gaps indicate that there are outliers present in our dataset which might need to be treated so as to get a better model accuracy later.
"""

df.skew() # acceptable range is +/-0.5

"""Here we see the skewness information present in our dataset. We will ignore quality since it is our target label in the dataset. Now taking a look at all the feature columns we see that fixed acidity, volatile acidity, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, sulphates and alcohol are all outside the acceptable range of +/-0.5. This skewness indicates outliers being present in our dataset that will need to be treated if required.

# Visualization
"""

plt.figure(figsize=(5,5))
sns.countplot(x ='quality', data = df)
plt.xlabel('Quality of Red Wine')
plt.ylabel('Count of Rows in the dataset')
plt.show()

"""In the countplot representation we see the various categories of red wine quality and it shows that the number of data present for quality score 5 and 6 is way higher than it's counterparts. This indicates an imbalance which will need to be rectified so that our machine learning model do not get biased to a certain value during prediction."""

index=0
labels = df['quality']
features = df.drop('quality', axis=1)

for col in features.items():
    plt.figure(figsize=(10,5))
    sns.barplot(x=labels, y=col[index], data=df, color="deeppink")
plt.tight_layout()
plt.show()

"""With the feature vs label barplot we are able to see the trend corresponding to the impact each has with respect to predicting the quality column (our target variable).

Observations regarding feature compared to the label are:
01. fixed acidity vs quality - no fixed pattern
02. volatile acidity vs quality - there is a decreasing trend
03. citric acid vs quality - there is an increasing trend
04. residual sugar vs quality - no fixed pattern
05. chlorides vs quality - there is a decreasing trend
06. free sulfur dioxide vs quality - no fixed pattern as it is increasing then decreasing
07. total sulfur dioxide vs quality - no fixed pattern as it is increasing then decreasing
08. density vs quality - no pattern at all
09. pH vs quality - no pattern at all
10. sulphates vs quality - there is an increasing trend
11. alcohol vs quality - there is an increasing trend

So here we can conclude that to get better quality wine citric acid, sulphates and alcohol columns play a major role.
"""

fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(10,5))
index = 0
ax = ax.flatten()
for col, value in df.items():
    sns.boxplot(y=col, data=df, ax=ax[index])
    index += 1
plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)
plt.show()

"""With the help of the above boxplot we are able to see the whisker details and outliers clearly. I am ignoring the continous outlier sections but the outliers that are single values and far away from the whiskers of the boxplot may need to be treated depending upon further analysis. Right now I am just trying to retain as much of data which is possible in the given dataset."""

fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(15,10))
index = 0
ax = ax.flatten()
for col, value in df.items():
    sns.distplot(value, ax=ax[index], hist=False, color="g", kde_kws={"shade": True})
    index += 1
plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)
plt.show()

"""The distribution plots show that few of the columns are in normal distribution category showing a proper bell shape curve. However, we do see skewness in most of the feature columns like citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, sulphates and alcohol columns. We are going to ignore the label column since it is a categorical column and will need to fix the imbalance data inside it.

With respect to the treatment of skewness and outliers I will perform the removal or treatment after I can see the accuracy dependency of the machine learning models.

# Correlation using a Heatmap

1. Positive correlation - A correlation of +1 indicates a perfect positive correlation, meaning that both variables move in the same direction together.

2. Negative correlation - A correlation of â€“1 indicates a perfect negative correlation, meaning that as one variable goes up, the other goes down.
"""

lower_triangle = np.tril(df.corr())
plt.figure(figsize=(5,5))
sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, square=True, fmt='0.3f',
            annot_kws={'size':5}, cmap="Spectral", mask=lower_triangle)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()

"""I see that the above heatmap shows the correlation matrix data wherein there are positive as well as negative correlations between the target label and other feture columns. A zero correlation indicates that there is no relationship between the variables. Looking at the above representation I see that quality column is positively correlated with alcohol and it is negatively correlated with the volatile acidity. The quality column is least correlated with residual sugar showing a coefficient value of 0.014 that close to 0. Similarly we can bifurcate all the other positively and negatively correlated feature columns with respect to the target label.

Also there are some highly positive and negative correlated feature columns that can pose the concern for multicollinearity. If the correlation coefficient, assuming it to be the variable 'r', is exactly +1 or -1, then it is called perfect multicollinearity. But even if this 'r' is close to -1 or +1 then one of the features should be removed from the model if at all possible.

Right now I see columns fixed acidity and citirc acid are positively correlated with a value of 0.672 which is close to 1. Similary, columns fixed acidity and density are positively correlated with a value of 0.668 again being close to 1. The other 2 column that's positively correlated are free sulfur dioxide and total sulfur dioxide with a value of 0.668 which is close to the value 1. The only negatively correlated columns that pop up are fixed acitidy and pH with a value -0.683 being close to the value -1.

We may need to deal with multicollinearity later if required to improve the accuracy of our machine learning models.

# Dropping a column
"""

#df = df.drop('free sulfur dioxide', axis=1)
df

"""I feel that free sulfur dioxide and total sulfur dioxide are both indicating towards the same feature of sulfur dioxide therefore I am dropping the free option and keeping just the total option in our dataset.

# Outlier removal
"""

df.shape

"""Confirming the number of columns and rows before removing the outliers from the dataset."""

# Z score method

z=np.abs(zscore(df))
threshold=3
np.where(z>3)

df=df[(z<3).all(axis=1)]
df

"""I have used the Z score method to get rid of outliers present in our dataset that are not in the acceptable range of +/-0.5 value of skewness."""

df.shape

"""Checking the number of rows present in the dataset after applying the outlier removal technique."""

# Percentage of Data Loss

data_loss=(1599-1464)/1599*100
# 1599 (number of rows in the original dataframe) and 1464 (number of rows after outlier removal)
data_loss

"""After removing the outliers we are checking the data loss percentage by comparing the rows in our original data set and the new data set post removal of the outliers.

# Splitting the dataset into 2 variables namely 'X' and 'Y' for feature and label
"""

X = df.drop('quality', axis=1)
Y = df['quality']

"""I have bifurcated the dataset into features and labels where X represents all the feature columns and Y represents the target label column.

### Taking care of class imbalance
"""

Y.value_counts()

"""Listing the values of our label column to count the number of rows occupied by each category. This indicates class imbalance that we will need to fix by using the oversampling method."""

# adding samples to make all the categorical quality values same

oversample = SMOTE()
X, Y = oversample.fit_resample(X, Y)

#df_resampled = pd.concat([pd.DataFrame(X, columns=X.columns), pd.DataFrame(Y, columns=['quality'])], axis=1)

# Plotting the distribution of 'quality' after SMOTE
#plt.figure(figsize=(5, 5))
#sns.countplot(x='quality', data=df_resampled)
#plt.xlabel('Quality of Red Wine (After SMOTE)')
#plt.ylabel('Count of Rows in the dataset')
#plt.title('Distribution of Quality Classes After SMOTE')
#plt.show()

"""SMOTE is the over sampling mechanism that we are using to ensure that all the categories present in our target label have the same value."""

Y.value_counts()

"""After applying over sampling we are one again listing the values of our label column to cross verify the updated information. Here we see that we have successfully resolved the class imbalance problem and now all the categories have same data ensuring that the machine learning model does not get biased towards one category."""

Y # Displaying just the label

"""### Label Binarization"""

Y = Y.apply(lambda y_value:1 if y_value>=7 else 0) # 1 is for good quality and 0 for bad (not good) quality
Y # Displaying the label after applying label binarization

"""Using the label binarization technique we have tagged the categories present in our target label to 2 major class that are 0 for bad quality wine and 1 for good quality wine."""

X # Displaying all the features except the label

"""### Feature Scaling"""

scaler = StandardScaler()
X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
X # Displaying all the features after applying scaling technique to avoid bias output

"""Even though all our feature columns were of float data type I was unhappy with the decimal place differences and was worried that it might make my model biased. Therefore I am using the Standard Scaler method to ensure all my feature columns have been standardized.

# Creating the training and testing data sets
"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)

"""I am taking 20 percent of the complete dataset for training purpose and the remaing 80 percent with be used to train the machine learning models

# Machine Learning Model for Classification and Evaluation Metrics
"""

results={}

# Classification Model Function

def classify(classifier,model, X, Y):
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)

    # Training the model
    model.fit(X_train, Y_train)

    # Predicting Y_test
    pred = model.predict(X_test)

    # Accuracy Score
    acc_score = (accuracy_score(Y_test, pred))*100
    print("Accuracy Score:", acc_score)

    # Classification Report
    class_report = classification_report(Y_test, pred)
    print("\nClassification Report:\n", class_report)

    # Cross Validation Score
    cv_score = (cross_val_score(model, X, Y, cv=5).mean())*100
    print("Cross Validation Score:", cv_score)

    # Result of accuracy minus cv scores
    result = acc_score - cv_score
    print("\nAccuracy Score - Cross Validation Score is", result)

    results.update({classifier:acc_score})

"""I have defined a class that will perform the train-test split, training of machine learning model, predicting the label value, getting the accuracy score, generating the classification report, getting the cross validation score and the result of difference between the accuracy score and cross validation score for any machine learning model that calls for this function."""

# Logistic Regression
model=LogisticRegression()
classify("LR",model, X, Y)

"""Created the Logistic Regression Model and checked for it's evaluation metrics."""

# Support Vector Classifier

model=SVC(C=1.0, kernel='rbf', gamma='auto', random_state=42)
classify("SVC",model, X, Y)

"""Created the Support Vector Classifier Model and checked for it's evaluation metrics."""

# Decision Tree Classifier

#model=DecisionTreeClassifier(random_state=21, max_depth=15)
#classify("DT",model, X, Y)

"""Created the Decision Tree Classifier Model and checked for it's evaluation metrics."""

# Random Forest Classifier

model=RandomForestClassifier(max_depth=15, random_state=111)
classify("RF",model, X, Y)

"""Created the Random Forest Classifier Model and checked for it's evaluation metrics."""

# K Neighbors Classifier

#model=KNeighborsClassifier(n_neighbors=15)
#classify("KNN",model, X, Y)

"""Created the K Neighbors Classifier Model and checked for it's evaluation metrics."""

# Extra Trees Classifier
#model=ExtraTreesClassifier()
#classify("ET",model, X, Y)

"""Created the Extra Trees Classifier Model and checked for it's evaluation metrics."""

# XGB Classifier
model=xgb.XGBClassifier(verbosity=0)
classify("XGB",model, X, Y)

"""Created the XGB Classifier Model and checked for it's evaluation metrics."""

import matplotlib.pyplot as plt

# Extracting keys and values
keys = list(results.keys())
values = list(results.values())

plt.figure(figsize=(5,5))  # Adjust the width and height as needed
# Creating the bar chart
plt.bar(keys, values)

# Adding title and labels
plt.title('Accuracy Comparision')
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')

# Show the plot
plt.show()